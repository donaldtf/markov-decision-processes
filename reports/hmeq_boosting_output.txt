Best parameters set found on development set:

{'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 20}

Grid scores on development set:

0.000 (+/-0.000) for {'learning_rate': 0.05, 'max_depth': 2, 'n_estimators': 5}
0.088 (+/-0.095) for {'learning_rate': 0.05, 'max_depth': 2, 'n_estimators': 10}
0.349 (+/-0.096) for {'learning_rate': 0.05, 'max_depth': 2, 'n_estimators': 15}
0.517 (+/-0.074) for {'learning_rate': 0.05, 'max_depth': 2, 'n_estimators': 20}
0.000 (+/-0.000) for {'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 5}
0.116 (+/-0.024) for {'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 10}
0.473 (+/-0.075) for {'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 15}
0.592 (+/-0.084) for {'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 20}
0.000 (+/-0.000) for {'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 5}
0.167 (+/-0.045) for {'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 10}
0.531 (+/-0.077) for {'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 15}
0.644 (+/-0.066) for {'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 20}
0.000 (+/-0.000) for {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 5}
0.260 (+/-0.112) for {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 10}
0.590 (+/-0.105) for {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 15}
0.654 (+/-0.075) for {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 20}
0.115 (+/-0.033) for {'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 5}
0.542 (+/-0.085) for {'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 10}
0.605 (+/-0.082) for {'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 15}
0.622 (+/-0.093) for {'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 20}
0.140 (+/-0.053) for {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 5}
0.598 (+/-0.085) for {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 10}
0.669 (+/-0.065) for {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 15}
0.680 (+/-0.069) for {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 20}
0.227 (+/-0.060) for {'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 5}
0.648 (+/-0.071) for {'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 10}
0.689 (+/-0.061) for {'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 15}
0.697 (+/-0.066) for {'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 20}
0.310 (+/-0.069) for {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 5}
0.660 (+/-0.074) for {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 10}
0.690 (+/-0.081) for {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 15}
0.702 (+/-0.072) for {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 20}
0.441 (+/-0.086) for {'learning_rate': 0.15, 'max_depth': 2, 'n_estimators': 5}
0.602 (+/-0.078) for {'learning_rate': 0.15, 'max_depth': 2, 'n_estimators': 10}
0.662 (+/-0.071) for {'learning_rate': 0.15, 'max_depth': 2, 'n_estimators': 15}
0.670 (+/-0.046) for {'learning_rate': 0.15, 'max_depth': 2, 'n_estimators': 20}
0.504 (+/-0.092) for {'learning_rate': 0.15, 'max_depth': 3, 'n_estimators': 5}
0.673 (+/-0.055) for {'learning_rate': 0.15, 'max_depth': 3, 'n_estimators': 10}
0.687 (+/-0.042) for {'learning_rate': 0.15, 'max_depth': 3, 'n_estimators': 15}
0.700 (+/-0.056) for {'learning_rate': 0.15, 'max_depth': 3, 'n_estimators': 20}
0.583 (+/-0.083) for {'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 5}
0.687 (+/-0.060) for {'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 10}
0.705 (+/-0.074) for {'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 15}
0.715 (+/-0.061) for {'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 20}
0.610 (+/-0.103) for {'learning_rate': 0.15, 'max_depth': 5, 'n_estimators': 5}
0.691 (+/-0.063) for {'learning_rate': 0.15, 'max_depth': 5, 'n_estimators': 10}
0.704 (+/-0.061) for {'learning_rate': 0.15, 'max_depth': 5, 'n_estimators': 15}
0.713 (+/-0.055) for {'learning_rate': 0.15, 'max_depth': 5, 'n_estimators': 20}

Detailed classification report:

The model is trained on the full development set.
The scores are computed on the full evaluation set.

Final Performance on Test Set
MSE: 0.1040268456375839

Accuracy Score: 89.59731543624162%

F1 Score: 0.7181818181818181

              precision    recall  f1-score   support

           0       0.92      0.95      0.94       477
           1       0.78      0.66      0.72       119

   micro avg       0.90      0.90      0.90       596
   macro avg       0.85      0.81      0.83       596
weighted avg       0.89      0.90      0.89       596


